Hyperparameter Optimization
===========================

The [DeepHyper package](https://github.com/deephyper/deephyper) for
AutoML (hyperparameter optimization and neural architecture search)
allows you to tune your deep learning models by searching hyperparmeter
or architecture space at scale. Balsam serves as an execution backend
for DeepHyper, which facilitates a very flexible coupling to your
existing model codes (any Python version, ML library, and even
data-parallel model training with MPI is supported).
